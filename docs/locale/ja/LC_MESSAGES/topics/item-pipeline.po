# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008â€“2021, Scrapy developers
# This file is distributed under the same license as the Scrapy package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Scrapy 2.5\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-10 01:26+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../topics/item-pipeline.rst:5
msgid "Item Pipeline"
msgstr ""

#: ../../topics/item-pipeline.rst:7
msgid ""
"After an item has been scraped by a spider, it is sent to the Item "
"Pipeline which processes it through several components that are executed "
"sequentially."
msgstr ""

#: ../../topics/item-pipeline.rst:10
msgid ""
"Each item pipeline component (sometimes referred as just \"Item "
"Pipeline\") is a Python class that implements a simple method. They "
"receive an item and perform an action over it, also deciding if the item "
"should continue through the pipeline or be dropped and no longer "
"processed."
msgstr ""

#: ../../topics/item-pipeline.rst:15
msgid "Typical uses of item pipelines are:"
msgstr ""

#: ../../topics/item-pipeline.rst:17
msgid "cleansing HTML data"
msgstr ""

#: ../../topics/item-pipeline.rst:18
msgid "validating scraped data (checking that the items contain certain fields)"
msgstr ""

#: ../../topics/item-pipeline.rst:19
msgid "checking for duplicates (and dropping them)"
msgstr ""

#: ../../topics/item-pipeline.rst:20
msgid "storing the scraped item in a database"
msgstr ""

#: ../../topics/item-pipeline.rst:24
msgid "Writing your own item pipeline"
msgstr ""

#: ../../topics/item-pipeline.rst:26
msgid ""
"Each item pipeline component is a Python class that must implement the "
"following method:"
msgstr ""

#: ../../topics/item-pipeline.rst:30
msgid "This method is called for every item pipeline component."
msgstr ""

#: ../../topics/item-pipeline.rst:32
msgid ""
"`item` is an :ref:`item object <item-types>`, see :ref:`supporting-item-"
"types`."
msgstr ""

#: ../../topics/item-pipeline.rst:35
msgid ""
":meth:`process_item` must either: return an :ref:`item object <item-"
"types>`, return a :class:`~twisted.internet.defer.Deferred` or raise a "
":exc:`~scrapy.exceptions.DropItem` exception."
msgstr ""

#: ../../topics/item-pipeline.rst:39
msgid "Dropped items are no longer processed by further pipeline components."
msgstr ""

#: ../../topics/item-pipeline.rst
msgid "Parameters"
msgstr ""

#: ../../topics/item-pipeline.rst:41
msgid "the scraped item"
msgstr ""

#: ../../topics/item-pipeline.rst:44
msgid "the spider which scraped the item"
msgstr ""

#: ../../topics/item-pipeline.rst:47
msgid "Additionally, they may also implement the following methods:"
msgstr ""

#: ../../topics/item-pipeline.rst:51
msgid "This method is called when the spider is opened."
msgstr ""

#: ../../topics/item-pipeline.rst:53
msgid "the spider which was opened"
msgstr ""

#: ../../topics/item-pipeline.rst:58
msgid "This method is called when the spider is closed."
msgstr ""

#: ../../topics/item-pipeline.rst:60
msgid "the spider which was closed"
msgstr ""

#: ../../topics/item-pipeline.rst:65
msgid ""
"If present, this classmethod is called to create a pipeline instance from"
" a :class:`~scrapy.crawler.Crawler`. It must return a new instance of the"
" pipeline. Crawler object provides access to all Scrapy core components "
"like settings and signals; it is a way for pipeline to access them and "
"hook its functionality into Scrapy."
msgstr ""

#: ../../topics/item-pipeline.rst:71
msgid "crawler that uses this pipeline"
msgstr ""

#: ../../topics/item-pipeline.rst:76
msgid "Item pipeline example"
msgstr ""

#: ../../topics/item-pipeline.rst:79
msgid "Price validation and dropping items with no prices"
msgstr ""

#: ../../topics/item-pipeline.rst:81
msgid ""
"Let's take a look at the following hypothetical pipeline that adjusts the"
" ``price`` attribute for those items that do not include VAT "
"(``price_excludes_vat`` attribute), and drops those items which don't "
"contain a price::"
msgstr ""

#: ../../topics/item-pipeline.rst:103
msgid "Write items to a JSON file"
msgstr ""

#: ../../topics/item-pipeline.rst:105
msgid ""
"The following pipeline stores all scraped items (from all spiders) into a"
" single ``items.jl`` file, containing one item per line serialized in "
"JSON format::"
msgstr ""

#: ../../topics/item-pipeline.rst:126
msgid ""
"The purpose of JsonWriterPipeline is just to introduce how to write item "
"pipelines. If you really want to store all scraped items into a JSON file"
" you should use the :ref:`Feed exports <topics-feed-exports>`."
msgstr ""

#: ../../topics/item-pipeline.rst:131
msgid "Write items to MongoDB"
msgstr ""

#: ../../topics/item-pipeline.rst:133
msgid ""
"In this example we'll write items to MongoDB_ using pymongo_. MongoDB "
"address and database name are specified in Scrapy settings; MongoDB "
"collection is named after item class."
msgstr ""

#: ../../topics/item-pipeline.rst:137
msgid ""
"The main point of this example is to show how to use :meth:`from_crawler`"
" method and how to clean up the resources properly.::"
msgstr ""

#: ../../topics/item-pipeline.rst:176
msgid "Take screenshot of item"
msgstr ""

#: ../../topics/item-pipeline.rst:178
msgid ""
"This example demonstrates how to use :doc:`coroutine syntax <coroutines>`"
" in the :meth:`process_item` method."
msgstr ""

#: ../../topics/item-pipeline.rst:181
msgid ""
"This item pipeline makes a request to a locally-running instance of "
"Splash_ to render a screenshot of the item URL. After the request "
"response is downloaded, the item pipeline saves the screenshot to a file "
"and adds the filename to the item."
msgstr ""

#: ../../topics/item-pipeline.rst:225
msgid "Duplicates filter"
msgstr ""

#: ../../topics/item-pipeline.rst:227
msgid ""
"A filter that looks for duplicate items, and drops those items that were "
"already processed. Let's say that our items have a unique id, but our "
"spider returns multiples items with the same id::"
msgstr ""

#: ../../topics/item-pipeline.rst:250
msgid "Activating an Item Pipeline component"
msgstr ""

#: ../../topics/item-pipeline.rst:252
msgid ""
"To activate an Item Pipeline component you must add its class to the "
":setting:`ITEM_PIPELINES` setting, like in the following example::"
msgstr ""

#: ../../topics/item-pipeline.rst:260
msgid ""
"The integer values you assign to classes in this setting determine the "
"order in which they run: items go through from lower valued to higher "
"valued classes. It's customary to define these numbers in the 0-1000 "
"range."
msgstr ""

